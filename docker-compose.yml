services:
  zookeeper:
    image: confluentinc/cp-zookeeper:${CONFLUENT_VERSION:-7.4.7}
    platform: ${PLATFORM:-linux/amd64}
    container_name: zookeeper
    restart: unless-stopped
    environment:
      ZOOKEEPER_SERVER_ID: 1
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
      ZOOKEEPER_INIT_LIMIT: 5
      ZOOKEEPER_SYNC_LIMIT: 2
    ports:
      - "2181:2181"
    healthcheck:
      test: nc -z localhost 2181 || exit 1
      start_period: 20s
      start_interval: 10s
      interval: 30s
      timeout: 30s
      retries: 5
    networks:
      - datalake

  kafka:
    image: confluentinc/cp-kafka:${CONFLUENT_VERSION:-7.4.7}
    platform: ${PLATFORM:-linux/amd64}
    container_name: kafka
    restart: unless-stopped
    depends_on:
      zookeeper:
        condition: service_healthy
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: "zookeeper:2181"
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: "PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT"
      KAFKA_ADVERTISED_LISTENERS: "PLAINTEXT://kafka:29092,PLAINTEXT_HOST://localhost:9092"
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "true"
      KAFKA_MESSAGE_MAX_BYTES: 10000000
      KAFKA_LOG4J_LOGGERS: "kafka.controller=INFO,kafka.producer.async.DefaultEventHandler=INFO,state.change.logger=INFO"
    ports:
      - "29092:29092"
      - "9092:9092"
      - "9101:9101"
    healthcheck:
      test: nc -z localhost 9092 || exit 1
      start_period: 20s
      interval: 30s
      timeout: 30s
      retries: 5
    networks:
      - datalake

  kafka-init-topics:
    image: confluentinc/cp-kafka:${CONFLUENT_VERSION:-7.4.7}
    platform: ${PLATFORM:-linux/amd64}
    container_name: kafka-init-topics
    depends_on:
      kafka:
        condition: service_healthy
    command: "bash -c 'echo Waiting for Kafka to be ready... && \
      cub kafka-ready -b kafka:29092 1 30 && \
      kafka-topics --create --topic hudi-test-topic --partitions 1 --replication-factor 1 --if-not-exists --bootstrap-server kafka:29092 && \
      kafka-topics --list --bootstrap-server kafka:29092'"
    networks:
      - datalake

  kafka-schema-registry:
    image: confluentinc/cp-schema-registry:${CONFLUENT_VERSION:-7.4.7}
    platform: ${PLATFORM:-linux/amd64}
    container_name: kafka-schema-registry
    restart: unless-stopped
    depends_on:
      kafka:
        condition: service_healthy
    environment:
      SCHEMA_REGISTRY_HOST_NAME: "kafka-schema-registry"
      SCHEMA_REGISTRY_KAFKASTORE_BOOTSTRAP_SERVERS: "kafka:29092"
      SCHEMA_REGISTRY_LISTENERS: "http://0.0.0.0:8081"
      SCHEMA_REGISTRY_LOG4J_ROOT_LOGLEVEL: "INFO"
      SCHEMA_REGISTRY_KAFKASTORE_TOPIC: "_schemas"
      SCHEMA_REGISTRY_DEBUG: "true"
    ports:
      - "8081:8081"
    healthcheck:
      test: nc -z localhost 8081 || exit 1
      start_period: 20s
      interval: 30s
      timeout: 30s
      retries: 5
    networks:
      - datalake

  kafka-rest:
    image: confluentinc/cp-kafka-rest:${CONFLUENT_VERSION:-7.4.7}
    platform: ${PLATFORM:-linux/amd64}
    container_name: kafka-rest
    restart: unless-stopped
    depends_on:
      kafka:
        condition: service_healthy
    environment:
      KAFKA_REST_SCHEMA_REGISTRY_URL: "http://kafka-schema-registry:8081"
      KAFKA_REST_HOST_NAME: "kafka-rest"
      KAFKA_REST_BOOTSTRAP_SERVERS: "kafka:29092"
      KAFKA_REST_LISTENERS: "http://0.0.0.0:8082"
    ports:
      - "8082:8082"
    healthcheck:
      test: nc -z localhost 8082 || exit 1
      start_period: 20s
      interval: 30s
      timeout: 30s
      retries: 5
    networks:
      - datalake

  kafka-connect:
    image: rangareddy1988/ranga-kafka-connect:${KAFKA_CONNECT_VERSION:-7.4.7}
    platform: ${PLATFORM:-linux/amd64}
    container_name: kafka-connect
    restart: unless-stopped
    depends_on:
      postgres:
        condition: service_healthy
      kafka:
        condition: service_healthy
      kafka-rest:
        condition: service_healthy
      hive-metastore:
        condition: service_healthy
    environment:
      CONNECT_BOOTSTRAP_SERVERS: "kafka:29092"
      CONNECT_GROUP_ID: "kafka-connect-group"
      CONNECT_LISTENERS: "http://0.0.0.0:8083"
      CONNECT_REST_ADVERTISED_HOST_NAME: "kafka-connect"
      CONNECT_REST_PORT: 8083
      CONNECT_OFFSET_FLUSH_INTERVAL_MS: 10000
      CONNECT_KEY_CONVERTER: "org.apache.kafka.connect.storage.StringConverter"
      CONNECT_VALUE_CONVERTER: "io.confluent.connect.avro.AvroConverter"
      CONNECT_VALUE_CONVERTER_SCHEMA_REGISTRY_URL: "http://kafka-schema-registry:8081"
      CONNECT_INTERNAL_KEY_CONVERTER: "org.apache.kafka.connect.json.JsonConverter"
      CONNECT_INTERNAL_VALUE_CONVERTER: "org.apache.kafka.connect.json.JsonConverter"
      CONNECT_LOG4J_ROOT_LOGLEVEL: "INFO"
      CONNECT_LOG4J_LOGGERS: "org.apache.kafka.connect.runtime.rest=WARN,org.apache.zookeeper=ERROR,org.I0Itec.zkclient=ERROR,org.reflections=ERROR"
      CONNECT_PLUGIN_PATH: "/usr/share/java,/usr/share/confluent-hub-components,/opt/connectors"
    ports:
      - "8083:8083"
    volumes:
      - ./debezium_configs:/opt/data/connector_configs
    healthcheck:
      test: nc -z localhost 8083 || exit 1
      start_period: 20s
      interval: 30s
      timeout: 30s
      retries: 5
    networks:
      - datalake

  kafka-cat:
    image: rangareddy1988/ranga-kafka-cat:${CONFLUENT_KAFKACAT_VERSION:-latest}
    platform: ${PLATFORM:-linux/amd64}
    container_name: kafka-cat
    restart: unless-stopped
    depends_on:
      kafka:
        condition: service_healthy
    networks:
      - datalake

  kafka-ui:
    image: provectuslabs/kafka-ui:${KAFKA_UI_VERSION:-latest}
    platform: ${PLATFORM:-linux/amd64}
    container_name: kafka-ui
    restart: unless-stopped
    depends_on:
      kafka:
        condition: service_healthy
      kafka-schema-registry:
        condition: service_healthy
      kafka-connect:
        condition: service_healthy
    environment:
      KAFKA_CLUSTERS_0_NAME: local
      KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS: kafka:29092
      KAFKA_CLUSTERS_0_SCHEMAREGISTRY: http://kafka-schema-registry:8081
      KAFKA_CLUSTERS_0_ZOOKEEPER: zookeeper:2181
      KAFKA_CLUSTERS_0_KAFKACONNECT_0_NAME: first
      KAFKA_CLUSTERS_0_KAFKACONNECT_0_ADDRESS: http://kafka-connect:8083
      KAFKA_CLUSTERS_0_AUDIT_TOPICAUDITENABLED: "true"
      KAFKA_CLUSTERS_0_AUDIT_CONSOLEAUDITENABLED: "true"
      DYNAMIC_CONFIG_ENABLED: "true"
    ports:
      - "9082:8080"
    healthcheck:
      test: wget --no-verbose --tries=1 --spider  http://localhost:8080/actuator/health
      start_period: 20s
      interval: 30s
      timeout: 10s
      retries: 5
    networks:
      - datalake

  hive-metastore:
    image: rangareddy1988/ranga-hive:${HIVE_VERSION:-4.0.0}
    platform: ${PLATFORM:-linux/amd64}
    container_name: hive-metastore
    restart: unless-stopped
    depends_on:
      postgres:
        condition: service_healthy
      minio:
        condition: service_healthy
    environment:
      DB_DRIVER: postgres
      SERVICE_NAME: "metastore"
      VERBOSE: "true"
    ports:
      - "9083:9083"
    volumes:
      - ./logs/metastore/:/tmp/hive/
    healthcheck:
      test: bash -c "exec 6<> /dev/tcp/localhost/9083"
      start_period: 50s
      start_interval: 20s
      interval: 50s
      timeout: 30s
      retries: 10
    networks:
      - datalake

  hive-server:
    image: rangareddy1988/ranga-hive:${HIVE_VERSION:-4.0.0}
    platform: ${PLATFORM:-linux/amd64}
    container_name: hive-server
    restart: unless-stopped
    depends_on:
      hive-metastore:
        condition: service_healthy
    environment:
      SERVICE_NAME: hiveserver2
      IS_RESUME: "true"
      HIVE_SERVER2_THRIFT_PORT: 10000
      SERVICE_OPTS: "-Dhive.metastore.uris=thrift://hive-metastore:9083"
      AWS_ACCESS_KEY: admin
      AWS_SECRET_ACCESS_KEY: password
    volumes:
      - ./logs/hiveserver/:/tmp/hive/
    ports:
      - "10000:10000"
      - "10002:10002"
    networks:
      - datalake

  spark-master:
    image: rangareddy1988/ranga-spark:${SPARK_VERSION:-3.5.3}
    platform: ${PLATFORM:-linux/amd64}
    container_name: spark-master
    restart: unless-stopped
    user: root
    depends_on:
      hive-metastore:
        condition: service_healthy
    environment:
      - SPARK_MODE=master
    ports:
      - "8080:8080"
      - "7077:7077"
      - "4040-4042:4040-4042"
      - "18080:18080"
    volumes:
      - ./data/spark-events:/opt/spark/spark-events
      - ./logs/spark-master:/var/log/spark
      - ./hudi_streamer:/opt/hudi_streamer
    healthcheck:
      test: bash -c "exec 6<> /dev/tcp/localhost/8080"
      start_period: 20s
      interval: 30s
      timeout: 30s
      retries: 5
    networks:
      - datalake

  spark-worker:
    image: rangareddy1988/ranga-spark:${SPARK_VERSION:-3.5.3}
    platform: ${PLATFORM:-linux/amd64}
    container_name: spark-worker
    restart: unless-stopped
    depends_on:
      spark-master:
        condition: service_healthy
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_HOST=spark-master
      - SPARK_WORKER_CORES=2
      - SPARK_WORKER_MEMORY=4G
      - SPARK_WORKER_WEBUI_PORT=8081
    ports:
      - "18081:8081"
    volumes:
      - ./logs/spark-worker:/var/log/spark
    healthcheck:
      test: bash -c "exec 6<> /dev/tcp/localhost/8081"
      start_period: 20s
      interval: 30s
      timeout: 30s
      retries: 5
    networks:
      - datalake

  postgres:
    image: postgres:${POSTGRES_VERSION:-16.4}
    platform: ${PLATFORM:-linux/amd64}
    container_name: postgres
    restart: unless-stopped
    environment:
      POSTGRES_USER: ${POSTGRES_USER:-postgres}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:-postgres}
      POSTGRES_DB: ${POSTGRES_DB:-postgres}
    ports:
      - "5432:5432"
    volumes:
      - ./db_scripts/postgres/db_init.sql:/docker-entrypoint-initdb.d/1_db_init.sql
      - ./db_scripts/postgres/employees.sql:/docker-entrypoint-initdb.d/2_employees.sql
      - ./db_scripts/postgres/multi_table_data.sql:/docker-entrypoint-initdb.d/3_data.sql
      - ./data/postgres:/var/lib/postgresql/data
    command: ["postgres", "-c", "wal_level=logical"]
    healthcheck:
      test: ["CMD", "psql", "-U", "postgres", "-c", "SELECT 1"]
      start_period: 20s
      interval: 30s
      timeout: 30s
      retries: 5
    networks:
      - datalake

  mysql:
    image: ubuntu/mysql:${MYSQL_VERSION:-8.0-20.04_edge}
    platform: ${PLATFORM:-linux/amd64}
    container_name: mysql
    restart: unless-stopped
    environment:
      - MYSQL_ROOT_PASSWORD=${MYSQL_ROOT_PASSWORD:-password}
      - MYSQL_DATABASE=${MYSQL_DATABASE:-default}
      - MYSQL_USER=${MYSQL_USER:-admin}
      - MYSQL_PASSWORD=${MYSQL_PASSWORD:-password}
    ports:
      - "3306:3306"
    volumes:
      - ./data/mysql:/var/lib/mysql
      - ./db_scripts/mysql:/docker-entrypoint-initdb.d
    command:
      [
        "--character-set-server=utf8mb4",
        "--collation-server=utf8mb4_unicode_ci",
        "--default-authentication-plugin=caching_sha2_password",
      ]
    healthcheck:
      test: ["CMD", "mysqladmin", "ping", "-h", "localhost", "--silent"]
      start_period: 20s
      interval: 30s
      timeout: 30s
      retries: 5
    networks:
      - datalake

  minio:
    image: minio/minio
    platform: ${PLATFORM:-linux/amd64}
    container_name: minio
    restart: unless-stopped
    environment:
      - MINIO_ROOT_USER=admin
      - MINIO_ROOT_PASSWORD=password
      - MINIO_DOMAIN=minio
    ports:
      - "9000:9000"
      - "9001:9001"
    volumes:
      - ./data/minio:/data
    command: ["server", "/data", "--console-address", ":9001"]
    healthcheck:
      test: bash -c ':> /dev/tcp/127.0.0.1/9000' || exit 1
      start_period: 20s
      interval: 30s
      timeout: 30s
      retries: 5
    networks:
      datalake:
        aliases:
          - warehouse.minio

  mc:
    image: minio/mc
    platform: ${PLATFORM:-linux/amd64}
    container_name: mc
    depends_on:
      minio:
        condition: service_healthy
    environment:
      - AWS_ACCESS_KEY_ID=admin
      - AWS_SECRET_ACCESS_KEY=password
      - AWS_REGION=us-east-1
      - S3_PATH_STYLE_ACCESS=true
    entrypoint: >
      /bin/sh -c " 
      until (/usr/bin/mc config host add minio http://minio:9000 admin password) do echo '...waiting...' && sleep 1; done; 
      /usr/bin/mc mb minio/warehouse;
      /usr/bin/mc mb minio/tmp;
      /usr/bin/mc policy set public minio/warehouse;
      /usr/bin/mc policy set public minio/tmp;
      tail -f /dev/null
      "
    networks:
      - datalake

  trino:
    image: rangareddy1988/ranga-trino:${TRINO_VERSION:-460}
    platform: ${PLATFORM:-linux/amd64}
    container_name: trino
    restart: unless-stopped
    depends_on:
      minio:
        condition: service_healthy
      hive-metastore:
        condition: service_healthy
    ports:
      - "9084:8080"
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/v1/info"]
      start_period: 90s
      interval: 30s
      timeout: 30s
      retries: 5
    networks:
      - datalake

  cloudbeaver:
    image: dbeaver/cloudbeaver:${CLOUDBEAVER_VERSION:-latest}
    container_name: cloudbeaver
    restart: unless-stopped
    depends_on:
      postgres:
        condition: service_healthy
      mysql:
        condition: service_healthy
    environment:
      admin_user: "cbadmin"
      admin_password: "Cbadmin123"
    ports:
      - "8978:8978"
    volumes:
      - ./data/cloudbeaver:/opt/cloudbeaver/workspace
    healthcheck:
      test: nc -z localhost 8978 || exit 1
      interval: 30s
      timeout: 30s
      retries: 5
    networks:
      - datalake

  jupyter-notebook:
    image: rangareddy1988/ranga-jupyter-notebook:${JUPYTER_NOTEBOOK_VERSION:-latest}
    platform: ${PLATFORM:-linux/amd64}
    container_name: jupyter-notebook
    restart: unless-stopped
    depends_on:
      minio:
        condition: service_healthy
      hive-metastore:
        condition: service_healthy
    environment:
      - AWS_ACCESS_KEY_ID=admin
      - AWS_SECRET_ACCESS_KEY=password
      - S3_ENDPOINT=http://minio:9000
    volumes:
      - ./data/notebooks:/home/jovyan/work
    ports:
      - "8888:8888"
    healthcheck:
      test: nc -z localhost 8888 || exit 1
      start_period: 20s
      start_interval: 10s
      interval: 30s
      timeout: 30s
      retries: 5
    networks:
      - datalake

  xtable:
    image: rangareddy1988/ranga-xtable:${XTABLE_VERSION:-latest}
    platform: ${PLATFORM:-linux/amd64}
    container_name: xtable
    restart: unless-stopped
    depends_on:
      minio:
        condition: service_healthy
      hive-metastore:
        condition: service_healthy
    environment:
      - IS_AWS_ENABLED=true
      - AWS_ACCESS_KEY_ID=admin
      - AWS_SECRET_ACCESS_KEY=password
      - AWS_ENDPOINT_URL=http://minio:9000
      - AWS_REGION=us-east-1
    networks:
      - datalake

  jobmanager:
    image: rangareddy1988/ranga-flink:${FLINK_VERSION:-latest}
    platform: ${PLATFORM:-linux/amd64}
    container_name: jobmanager
    restart: unless-stopped
    depends_on:
      kafka:
        condition: service_healthy
      minio:
        condition: service_healthy
      hive-metastore:
        condition: service_healthy
    environment:
      - |
        FLINK_PROPERTIES=
        jobmanager.rpc.address: jobmanager
        rest.address: 0.0.0.0
        rest.bind-address: 0.0.0.0
      - AWS_ACCESS_KEY_ID=admin
      - AWS_SECRET_ACCESS_KEY=password
      - AWS_ENDPOINT_URL=http://minio:9000
      - AWS_REGION=us-east-1
      - AWS_DEFAULT_REGION=us-east-1
      - S3_ENDPOINT=http://minio:9000
      - S3_PATH_STYLE_ACCESS=true
    command: jobmanager
    ports:
      - "8084:8084"
      - "6123:6123"
      - "6124:6124"
    networks:
      - datalake

  taskmanager:
    image: rangareddy1988/ranga-flink:${FLINK_VERSION:-latest}
    platform: ${PLATFORM:-linux/amd64}
    container_name: taskmanager
    restart: unless-stopped
    depends_on:
      - jobmanager
    environment:
      - |
        FLINK_PROPERTIES=
        jobmanager.rpc.address: jobmanager
        taskmanager.numberOfTaskSlots: 4
        taskmanager.bind-host: 0.0.0.0
      - AWS_ACCESS_KEY_ID=admin
      - AWS_SECRET_ACCESS_KEY=password
      - AWS_ENDPOINT_URL=http://minio:9000
      - AWS_REGION=us-east-1
      - AWS_DEFAULT_REGION=us-east-1
      - S3_ENDPOINT=http://minio:9000
      - S3_PATH_STYLE_ACCESS=true
    command: taskmanager
    ports:
      - "6121:6121"
      - "6122:6122"
    networks:
      - datalake

networks:
  datalake:
    name: datalake
