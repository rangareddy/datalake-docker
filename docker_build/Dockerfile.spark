FROM python:3.10-bullseye

SHELL ["/bin/bash", "-c"]

LABEL maintainer="Ranga Reddy <rangareddy.avula@gmail.com>"
LABEL description="Datalake Spark image"

RUN set -ex; \
  apt-get update && \
  apt-get --fix-broken install -y --no-install-recommends \
  sudo curl telnet wget tar vim ssh \
  unzip rsync openjdk-11-jdk \
  build-essential software-properties-common && \
  apt-get clean && \
  rm -rf /var/lib/apt/lists/*

ARG SPARK_VERSION=${SPARK_VERSION:-3.5.5}
ARG SCALA_VERSION=${SCALA_VERSION:-2.12}
ARG SPARK_HOME=${SPARK_HOME:-/opt/spark}
ARG HUDI_VERSION=${HUDI_VERSION:-1.0.2}
ARG ICEBERG_VERSION=${ICEBERG_VERSION:-1.9.0}
ARG DELTA_VERSION=${DELTA_VERSION:-3.3.1}
ARG APACHE_URL="https://repo1.maven.org/maven2/org/apache"

ENV SPARK_VERSION=${SPARK_VERSION:-3.5.5} \
  SPARK_MAJOR_VERSION=${SPARK_MAJOR_VERSION:-3.5} \
  SPARK_HOME=$SPARK_HOME \
  SPARK_CONF=$SPARK_HOME/conf \
  SPARK_CONF_DIR=/etc/spark/conf \
  SPARK_LOG_DIR=${SPARK_LOG_DIR:-/var/log/spark} \
  HUDI_HOME=${HUDI_HOME:-/opt/hudi} \
  HUDI_VERSION=${HUDI_VERSION:-1.0.2} \
  DELTA_HOME=${DELTA_HOME:-/opt/delta} \
  DELTA_VERSION=${DELTA_VERSION:-3.3.1} \
  ICEBERG_HOME=${ICEBERG_HOME:-/opt/iceberg} \
  ICEBERG_VERSION=${ICEBERG_VERSION:-1.9.0} \
  PATH="${SPARK_HOME}/sbin:${SPARK_HOME}/bin:${PATH}"

COPY requirements.txt /tmp/requirements.txt
RUN  pip install --upgrade pip && \
  pip install faker && \
  pip install --no-cache-dir -r /tmp/requirements.txt && \
  python3 -m spylon_kernel install && \
  curl -s https://github.com/SpencerPark/IJava/releases/download/v1.3.0/ijava-1.3.0.zip -Lo ijava-1.3.0.zip \
  && unzip ijava-1.3.0.zip \
  && python3 install.py --sys-prefix \
  && rm ijava-1.3.0.zip

COPY software/spark-${SPARK_VERSION}-bin-hadoop3.tgz /tmp/spark-${SPARK_VERSION}-bin-hadoop3.tgz

RUN mkdir -p ${SPARK_HOME} && \
  mkdir -p ${SPARK_HOME}/spark-events && \
  mkdir -p $SPARK_LOG_DIR && \
  tar xzf /tmp/spark-${SPARK_VERSION}-bin-hadoop3.tgz --directory ${SPARK_HOME} --strip-components 1 && \
  rm -rf /tmp/spark-${SPARK_VERSION}-bin-hadoop3.tgz && \
  wget -P $SPARK_HOME/jars/ $APACHE_URL/spark/spark-avro_${SCALA_VERSION}/${SPARK_VERSION}/spark-avro_${SCALA_VERSION}-${SPARK_VERSION}.jar

COPY hadoop-s3-jars/* $SPARK_HOME/jars/
COPY db_connector_jars/* $SPARK_HOME/jars/
COPY conf/spark/* $SPARK_CONF/
COPY conf/hadoop/core-site.xml $SPARK_CONF/
RUN mkdir -p /etc/spark && ln -sf $SPARK_CONF $SPARK_CONF_DIR

ARG ICEBERG_JAR=iceberg-spark-runtime-${SPARK_MAJOR_VERSION}_${SCALA_VERSION}-${ICEBERG_VERSION}.jar
ARG DELTA_JAR=delta-spark_${SCALA_VERSION}-${DELTA_VERSION}.jar
ARG HUDI_JAR=hudi-spark${SPARK_MAJOR_VERSION}-bundle_${SCALA_VERSION}-${HUDI_VERSION}.jar

RUN mkdir -p $HUDI_HOME $DELTA_HOME $ICEBERG_HOME && \
  wget -P $ICEBERG_HOME $APACHE_URL/iceberg/iceberg-spark-runtime-${SPARK_MAJOR_VERSION}_${SCALA_VERSION}/$ICEBERG_VERSION/$ICEBERG_JAR && \
  wget -P $DELTA_HOME/ https://repo1.maven.org/maven2/io/delta/delta-spark_${SCALA_VERSION}/${DELTA_VERSION}/$DELTA_JAR && \
  wget -P $HUDI_HOME/ ${APACHE_URL}/hudi/hudi-hive-sync/${HUDI_VERSION}/hudi-hive-sync-${HUDI_VERSION}.jar  && \
  wget -P $HUDI_HOME/ ${APACHE_URL}/hudi/hudi-hive-sync-bundle/${HUDI_VERSION}/hudi-hive-sync-bundle-${HUDI_VERSION}.jar && \
  wget -P $HUDI_HOME/ ${APACHE_URL}/hudi/hudi-hadoop-mr/${HUDI_VERSION}/hudi-hadoop-mr-${HUDI_VERSION}.jar  && \
  wget -P $HUDI_HOME/ ${APACHE_URL}/hudi/hudi-spark${SPARK_MAJOR_VERSION}-bundle_${SCALA_VERSION}/${HUDI_VERSION}/$HUDI_JAR && \
  wget -P $HUDI_HOME/ ${APACHE_URL}/hudi/hudi-utilities-bundle_${SCALA_VERSION}/${HUDI_VERSION}/hudi-utilities-bundle_${SCALA_VERSION}-${HUDI_VERSION}.jar && \
  wget -P $HUDI_HOME/ ${APACHE_URL}/hudi/hudi-utilities-slim-bundle_${SCALA_VERSION}/${HUDI_VERSION}/hudi-utilities-slim-bundle_${SCALA_VERSION}-${HUDI_VERSION}.jar

COPY scripts/spark/entrypoint.sh /opt/entrypoint.sh
COPY check_service_status_utility.sh /opt/check_service_status_utility.sh

RUN chmod 755 /opt/entrypoint.sh /opt/check_service_status_utility.sh
WORKDIR $SPARK_HOME

ENTRYPOINT ["/opt/entrypoint.sh"]